{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "name": "Sentiment Analysis on Rotten Tomatoes Movie Review with CNN BiLSTM_new version.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Zqvsv1Q3D-Mx",
        "6fxR0c1GD-NA",
        "5S78Tm-oD-NU",
        "hGay2jUhD-Nb",
        "XTOZZsjoD-Nf",
        "uKp1b30tD-Nm",
        "ex7QS77eD-Nu",
        "BsTr5NE9D-N5",
        "PglXIMv4D-N_",
        "ktnH4DuDD-OG",
        "novXVG3ZD-OT",
        "xKVO8VxID-Oi"
      ],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alvinsbkt/sentiment-analysis-rotten-tomatoes/blob/main/Sentiment_Analysis_on_Rotten_Tomatoes_Movie_Review.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IA5UeW7cEGZN",
        "outputId": "5f02575e-96a6-412d-ce8e-922cc12514fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQLljsdKD-L-"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "import datetime\n",
        "#import lightgbm as lgb\n",
        "from scipy import stats\n",
        "from scipy.sparse import hstack, csr_matrix\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "#from wordcloud import WordCloud\n",
        "from collections import Counter\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.util import ngrams\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "pd.set_option('max_colwidth',400)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fk1XznzSD-MF"
      },
      "source": [
        "# Reading the input files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7_Vz0T-D-MF"
      },
      "source": [
        "train = pd.read_csv('/content/drive/My Drive/WebMining/train.tsv', sep=\"\\t\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ld_xsI09D-MI",
        "outputId": "3d0da8a3-1a05-4a02-d012-62ff105a5056",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        }
      },
      "source": [
        "train.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PhraseId</th>\n",
              "      <th>SentenceId</th>\n",
              "      <th>Phrase</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>A series of escapades demonstrating the adage that what is good for the goose is also good for the gander , some of which occasionally amuses but none of which amounts to much of a story .</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>A series of escapades demonstrating the adage that what is good for the goose</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>A series</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>series</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>of escapades demonstrating the adage that what is good for the goose</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>of</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>escapades demonstrating the adage that what is good for the goose</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>escapades</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>demonstrating the adage that what is good for the goose</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PhraseId  ...  Sentiment\n",
              "0         1  ...          1\n",
              "1         2  ...          2\n",
              "2         3  ...          2\n",
              "3         4  ...          2\n",
              "4         5  ...          2\n",
              "5         6  ...          2\n",
              "6         7  ...          2\n",
              "7         8  ...          2\n",
              "8         9  ...          2\n",
              "9        10  ...          2\n",
              "\n",
              "[10 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94mNcPk8D-MM",
        "outputId": "fa481cf1-c868-4dc9-d4e7-c86d382e7186",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 614
        }
      },
      "source": [
        "train.loc[train.SentenceId == 2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PhraseId</th>\n",
              "      <th>SentenceId</th>\n",
              "      <th>Phrase</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>64</td>\n",
              "      <td>2</td>\n",
              "      <td>This quiet , introspective and entertaining independent is worth seeking .</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>65</td>\n",
              "      <td>2</td>\n",
              "      <td>This quiet , introspective and entertaining independent</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65</th>\n",
              "      <td>66</td>\n",
              "      <td>2</td>\n",
              "      <td>This</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66</th>\n",
              "      <td>67</td>\n",
              "      <td>2</td>\n",
              "      <td>quiet , introspective and entertaining independent</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67</th>\n",
              "      <td>68</td>\n",
              "      <td>2</td>\n",
              "      <td>quiet , introspective and entertaining</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68</th>\n",
              "      <td>69</td>\n",
              "      <td>2</td>\n",
              "      <td>quiet</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69</th>\n",
              "      <td>70</td>\n",
              "      <td>2</td>\n",
              "      <td>, introspective and entertaining</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>71</td>\n",
              "      <td>2</td>\n",
              "      <td>introspective and entertaining</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td>72</td>\n",
              "      <td>2</td>\n",
              "      <td>introspective and</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72</th>\n",
              "      <td>73</td>\n",
              "      <td>2</td>\n",
              "      <td>introspective</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73</th>\n",
              "      <td>74</td>\n",
              "      <td>2</td>\n",
              "      <td>and</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74</th>\n",
              "      <td>75</td>\n",
              "      <td>2</td>\n",
              "      <td>entertaining</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75</th>\n",
              "      <td>76</td>\n",
              "      <td>2</td>\n",
              "      <td>independent</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>77</td>\n",
              "      <td>2</td>\n",
              "      <td>is worth seeking .</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77</th>\n",
              "      <td>78</td>\n",
              "      <td>2</td>\n",
              "      <td>is worth seeking</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td>79</td>\n",
              "      <td>2</td>\n",
              "      <td>is worth</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79</th>\n",
              "      <td>80</td>\n",
              "      <td>2</td>\n",
              "      <td>worth</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80</th>\n",
              "      <td>81</td>\n",
              "      <td>2</td>\n",
              "      <td>seeking</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    PhraseId  ...  Sentiment\n",
              "63        64  ...          4\n",
              "64        65  ...          3\n",
              "65        66  ...          2\n",
              "66        67  ...          4\n",
              "67        68  ...          3\n",
              "68        69  ...          2\n",
              "69        70  ...          3\n",
              "70        71  ...          3\n",
              "71        72  ...          3\n",
              "72        73  ...          2\n",
              "73        74  ...          2\n",
              "74        75  ...          4\n",
              "75        76  ...          2\n",
              "76        77  ...          3\n",
              "77        78  ...          4\n",
              "78        79  ...          2\n",
              "79        80  ...          2\n",
              "80        81  ...          2\n",
              "\n",
              "[18 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwgZsds6D-MT",
        "outputId": "3a6ddbc2-3ceb-43e3-ac12-37d7e81d837f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "train['Sentiment'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2    79582\n",
              "3    32927\n",
              "1    27273\n",
              "4     9206\n",
              "0     7072\n",
              "Name: Sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPt_jwGHD-MX"
      },
      "source": [
        "# Cleaning the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6gKVOol9D-MX"
      },
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import FreqDist\n",
        "from nltk.stem import SnowballStemmer,WordNetLemmatizer\n",
        "stemmer=SnowballStemmer('english')\n",
        "lemma=WordNetLemmatizer()\n",
        "from string import punctuation\n",
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4nQ13v4D-Mc"
      },
      "source": [
        "def clean_review(review_col):\n",
        "    review_corpus=[]\n",
        "    for i in range(0,len(review_col)):\n",
        "        review=str(review_col[i])\n",
        "        review=re.sub('[^a-zA-Z]',' ',review)\n",
        "        \n",
        "        review=[lemma.lemmatize(w) for w in word_tokenize(str(review).lower())]\n",
        "        review=' '.join(review)\n",
        "        review_corpus.append(review)\n",
        "    return review_corpus"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5VT3cgIEmwu",
        "outputId": "95dcbb09-0e65-4d6c-f18c-3a7b89804ab1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hstuYYp0D-Mf"
      },
      "source": [
        "train['clean_review']=clean_review(train.Phrase.values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1NRZDD8D-Mh",
        "outputId": "14e0e2ef-ae38-4cce-d097-2025648cabfd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        }
      },
      "source": [
        "train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PhraseId</th>\n",
              "      <th>SentenceId</th>\n",
              "      <th>Phrase</th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>clean_review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>A series of escapades demonstrating the adage that what is good for the goose is also good for the gander , some of which occasionally amuses but none of which amounts to much of a story .</td>\n",
              "      <td>1</td>\n",
              "      <td>a series of escapade demonstrating the adage that what is good for the goose is also good for the gander some of which occasionally amuses but none of which amount to much of a story</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>A series of escapades demonstrating the adage that what is good for the goose</td>\n",
              "      <td>2</td>\n",
              "      <td>a series of escapade demonstrating the adage that what is good for the goose</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>A series</td>\n",
              "      <td>2</td>\n",
              "      <td>a series</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>2</td>\n",
              "      <td>a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>series</td>\n",
              "      <td>2</td>\n",
              "      <td>series</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PhraseId  ...                                                                                                                                                                            clean_review\n",
              "0         1  ...  a series of escapade demonstrating the adage that what is good for the goose is also good for the gander some of which occasionally amuses but none of which amount to much of a story\n",
              "1         2  ...                                                                                                            a series of escapade demonstrating the adage that what is good for the goose\n",
              "2         3  ...                                                                                                                                                                                a series\n",
              "3         4  ...                                                                                                                                                                                       a\n",
              "4         5  ...                                                                                                                                                                                  series\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGnXYZ-1kvMg"
      },
      "source": [
        "tokenizer = keras.preprocessing.text.Tokenizer()\n",
        "tokenizer.fit_on_texts(newdf['cleaning'])\n",
        "sequences = tokenizer.texts_to_sequences(newdf['cleaning'])\n",
        "print('Found %s unique tokens.' %len(tokenizer.word_index))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_E0fWt9Akw6G"
      },
      "source": [
        "data = keras.preprocessing.sequence.pad_sequences(sequences)\n",
        "labels = np.array(pd.get_dummies((newdf['sentiment'])))\n",
        "print('Shape of review tensor:', data.shape)\n",
        "print('shape of sentiment tensor:', labels.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K4FvkShAD-Ml"
      },
      "source": [
        "# Balancing the data by Resampling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OxFKbE4ND-Mm"
      },
      "source": [
        "from sklearn.utils import resample\n",
        "train_2 = train[train['Sentiment']==2]\n",
        "train_1 = train[train['Sentiment']==1]\n",
        "train_3 = train[train['Sentiment']==3]\n",
        "train_4 = train[train['Sentiment']==4]\n",
        "train_5 = train[train['Sentiment']==0]\n",
        "train_2_sample = resample(train_2,replace=True,n_samples=75000,random_state=123)\n",
        "train_1_sample = resample(train_1,replace=True,n_samples=75000,random_state=123)\n",
        "train_3_sample = resample(train_3,replace=True,n_samples=75000,random_state=123)\n",
        "train_4_sample = resample(train_4,replace=True,n_samples=75000,random_state=123)\n",
        "train_5_sample = resample(train_5,replace=True,n_samples=75000,random_state=123)\n",
        "\n",
        "df_upsampled = pd.concat([train_2, train_1_sample,train_3_sample,train_4_sample,train_5_sample])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "U8VH5PdwD-Mr",
        "outputId": "56c7b212-37b6-4c51-c6ca-f905acb01f77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "df_upsampled.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PhraseId</th>\n",
              "      <th>SentenceId</th>\n",
              "      <th>Phrase</th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>clean_review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>A series of escapades demonstrating the adage that what is good for the goose</td>\n",
              "      <td>2</td>\n",
              "      <td>a series of escapade demonstrating the adage that what is good for the goose</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>A series</td>\n",
              "      <td>2</td>\n",
              "      <td>a series</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>2</td>\n",
              "      <td>a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>series</td>\n",
              "      <td>2</td>\n",
              "      <td>series</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>of escapades demonstrating the adage that what is good for the goose</td>\n",
              "      <td>2</td>\n",
              "      <td>of escapade demonstrating the adage that what is good for the goose</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PhraseId  ...                                                                  clean_review\n",
              "1         2  ...  a series of escapade demonstrating the adage that what is good for the goose\n",
              "2         3  ...                                                                      a series\n",
              "3         4  ...                                                                             a\n",
              "4         5  ...                                                                        series\n",
              "5         6  ...           of escapade demonstrating the adage that what is good for the goose\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zqvsv1Q3D-Mx"
      },
      "source": [
        "# Data Processing for ML"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LzeNBx2tD-Mx"
      },
      "source": [
        "text = ' '.join(df_upsampled.loc[df_upsampled.Sentiment == 4, 'Phrase'].values)\n",
        "text_trigrams = [i for i in ngrams(text.split(), 3)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBY_KT7oD-Mz",
        "outputId": "343b7c0d-44f9-4b26-8740-cc664eff73cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 553
        }
      },
      "source": [
        "Counter(text_trigrams).most_common(30)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(('one', 'of', 'the'), 1644),\n",
              " (('of', 'the', 'year'), 832),\n",
              " (('of', 'the', 'best'), 677),\n",
              " (('of', 'the', 'most'), 612),\n",
              " (('is', 'one', 'of'), 407),\n",
              " (('One', 'of', 'the'), 370),\n",
              " ((',', 'and', 'the'), 333),\n",
              " (('the', 'year', \"'s\"), 326),\n",
              " (('It', \"'s\", 'a'), 323),\n",
              " (('the', 'edge', 'of'), 300),\n",
              " (('it', \"'s\", 'a'), 299),\n",
              " (('a', 'movie', 'that'), 297),\n",
              " (('of', 'your', 'seat'), 273),\n",
              " (('the', 'film', 'is'), 267),\n",
              " (('the', 'kind', 'of'), 267),\n",
              " (('.', 'is', 'a'), 264),\n",
              " (('the', 'film', \"'s\"), 264),\n",
              " (('as', 'one', 'of'), 254),\n",
              " ((',', 'the', 'film'), 253),\n",
              " (('edge', 'of', 'your'), 249),\n",
              " ((',', 'this', 'is'), 236),\n",
              " (('as', 'well', 'as'), 231),\n",
              " ((',', 'it', \"'s\"), 226),\n",
              " (('film', 'that', 'is'), 223),\n",
              " (('.', 'It', \"'s\"), 218),\n",
              " (('a', 'film', 'that'), 211),\n",
              " ((',', 'funny', ','), 208),\n",
              " (('some', 'of', 'the'), 206),\n",
              " (('year', \"'s\", 'best'), 188),\n",
              " (('a', 'solid', 'cast'), 178)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdG6mcawD-M2"
      },
      "source": [
        "tokenizer = TweetTokenizer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5LPMKetD-M4",
        "outputId": "a55de1ee-1bda-4f77-8dbd-13d77a53085f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "source": [
        "vectorizer = TfidfVectorizer(ngram_range=(1, 2), tokenizer=tokenizer.tokenize)\n",
        "full_text = list(df_upsampled['clean_review'].values)\n",
        "vectorizer.fit(full_text)\n",
        "df_upsampled_vectorized = vectorizer.transform(df_upsampled['clean_review'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:507: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SoVVmvh0D-M8"
      },
      "source": [
        "y = df_upsampled['Sentiment']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6fxR0c1GD-NA"
      },
      "source": [
        "# Applying ML algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUnpaZx7D-NR",
        "outputId": "a26ddd21-8a8e-40c1-fc62-4c19b2bc4529",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        }
      },
      "source": [
        "from keras.utils import to_categorical\n",
        "X = df_upsampled['clean_review']\n",
        "#test_set = test['clean review']\n",
        "#Y = train['Sentiment']\n",
        "Y = to_categorical(df_upsampled['Sentiment'].values)\n",
        "print(Y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " ...\n",
            " [1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5S78Tm-oD-NU"
      },
      "source": [
        "# splitting training set into training and validation set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCQZsn7rD-NU"
      },
      "source": [
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.25, random_state=123)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbtDBibQD-NW",
        "outputId": "9846caa2-c712-4aa0-f55b-084030b1266f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "print(X_train.shape,Y_train.shape)\n",
        "print(X_val.shape,Y_val.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(284686,) (284686, 5)\n",
            "(94896,) (94896, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mA2VOMyiD-NZ"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hGay2jUhD-Nb"
      },
      "source": [
        "# Total number of words/features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFjlrSpqD-Nc",
        "outputId": "bbf932f6-73bf-414b-a734-03d21e2364b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "all_words=' '.join(X_train)\n",
        "all_words=word_tokenize(all_words)\n",
        "#print(all_words)\n",
        "dist=FreqDist(all_words)\n",
        "\n",
        "num_unique_word=len(dist)\n",
        "num_unique_word\n",
        "#X_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13728"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XTOZZsjoD-Nf"
      },
      "source": [
        "# Number of words for each phrase/text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hay0ymkQD-Ng",
        "outputId": "d985e0ce-c414-4c50-b10d-0f5ad32132e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "r_len=[]\n",
        "for text in X_train:\n",
        "    word=word_tokenize(text)\n",
        "  #  print(text)\n",
        "    l=len(word)\n",
        "    r_len.append(l)\n",
        "    \n",
        "MAX_REVIEW_LEN=np.max(r_len)\n",
        "max_words = MAX_REVIEW_LEN\n",
        "max_words"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "48"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCbscwSlD-Ni"
      },
      "source": [
        "max_features = num_unique_word\n",
        "max_words = MAX_REVIEW_LEN\n",
        "batch_size = 128\n",
        "epochs = 30\n",
        "num_classes=5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BSj-b93WD-Nk"
      },
      "source": [
        "from tensorflow.python.keras.models import Sequential\n",
        "from tensorflow.python.keras.layers import Dense, GRU, Embedding\n",
        "from tensorflow.python.keras.optimizers import Adam\n",
        "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.python.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uKp1b30tD-Nm"
      },
      "source": [
        "# Tokenizing the words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CEZQJfM2D-Nn"
      },
      "source": [
        "tokenizer = Tokenizer(num_words=max_features)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "X_train = tokenizer.texts_to_sequences(X_train)\n",
        "X_val = tokenizer.texts_to_sequences(X_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ex7QS77eD-Nu"
      },
      "source": [
        "# Sequence Padding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bn8bjvpZD-Nu"
      },
      "source": [
        "from keras.preprocessing import sequence,text\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.models import Sequential\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "X_train = sequence.pad_sequences(X_train, maxlen=max_words)\n",
        "X_val = sequence.pad_sequences(X_val, maxlen=max_words)\n",
        "#print(X_train.shape,X_val.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcxNvPG1D-Nz"
      },
      "source": [
        "from keras.preprocessing import sequence,text\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Dropout,Embedding,LSTM,Conv1D,GlobalMaxPooling1D,Flatten,MaxPooling1D,GRU,SpatialDropout1D,Bidirectional\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.utils import to_categorical\n",
        "from keras.losses import categorical_crossentropy\n",
        "from keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report,f1_score\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BsTr5NE9D-N5"
      },
      "source": [
        "#LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPVM6qVEGGxJ"
      },
      "source": [
        "# importing required packages\n",
        "import re\n",
        "import csv\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM, Bidirectional\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers.convolutional import MaxPooling1D\n",
        "from keras import callbacks\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import load_model\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from keras.utils import np_utils\n",
        "\n",
        "# fix random seed for reproducibility\n",
        "np.random.seed(7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xF4gYGisD-N6",
        "outputId": "d069baa9-ae4f-45d7-813d-e592126b5c91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "model1=Sequential()\n",
        "model1.add(Embedding(max_features,100))\n",
        "model1.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
        "model1.add(MaxPooling1D(pool_size=2))\n",
        "model1.add(Bidirectional(LSTM(64,dropout=0.4, recurrent_dropout=0.4,return_sequences=True)))\n",
        "model1.add(Bidirectional(LSTM(32,dropout=0.5, recurrent_dropout=0.5,return_sequences=False)))\n",
        "model1.add(Dense(num_classes,activation='softmax'))\n",
        "\n",
        "\n",
        "model1.compile(loss='categorical_crossentropy',optimizer=Adam(lr=0.001),metrics=['accuracy'])\n",
        "model1.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, None, 100)         1372800   \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, None, 32)          9632      \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, None, 32)          0         \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, None, 128)         49664     \n",
            "_________________________________________________________________\n",
            "bidirectional_2 (Bidirection (None, 64)                41216     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 5)                 325       \n",
            "=================================================================\n",
            "Total params: 1,473,637\n",
            "Trainable params: 1,473,637\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PglXIMv4D-N_"
      },
      "source": [
        "# Fitting the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWc1Cc6dD-OA",
        "outputId": "2a63fe32-65dc-4c06-f015-a7c1dc6c30d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        }
      },
      "source": [
        "#%%time\n",
        "model1.fit(X_train, Y_train, validation_data=(X_val, Y_val),epochs=epochs, batch_size=batch_size, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 284686 samples, validate on 94896 samples\n",
            "Epoch 1/10\n",
            "284686/284686 [==============================] - 348s 1ms/step - loss: 0.9493 - accuracy: 0.6030 - val_loss: 0.7616 - val_accuracy: 0.6907\n",
            "Epoch 2/10\n",
            "284686/284686 [==============================] - 346s 1ms/step - loss: 0.7191 - accuracy: 0.7121 - val_loss: 0.6697 - val_accuracy: 0.7344\n",
            "Epoch 3/10\n",
            "284686/284686 [==============================] - 347s 1ms/step - loss: 0.6370 - accuracy: 0.7488 - val_loss: 0.6264 - val_accuracy: 0.7566\n",
            "Epoch 4/10\n",
            "284686/284686 [==============================] - 344s 1ms/step - loss: 0.5857 - accuracy: 0.7726 - val_loss: 0.5996 - val_accuracy: 0.7698\n",
            "Epoch 5/10\n",
            "284686/284686 [==============================] - 338s 1ms/step - loss: 0.5491 - accuracy: 0.7874 - val_loss: 0.5707 - val_accuracy: 0.7843\n",
            "Epoch 6/10\n",
            "284686/284686 [==============================] - 343s 1ms/step - loss: 0.5228 - accuracy: 0.8003 - val_loss: 0.5602 - val_accuracy: 0.7881\n",
            "Epoch 7/10\n",
            "284686/284686 [==============================] - 342s 1ms/step - loss: 0.4995 - accuracy: 0.8099 - val_loss: 0.5443 - val_accuracy: 0.7979\n",
            "Epoch 8/10\n",
            "284686/284686 [==============================] - 342s 1ms/step - loss: 0.4815 - accuracy: 0.8181 - val_loss: 0.5380 - val_accuracy: 0.8006\n",
            "Epoch 9/10\n",
            "284686/284686 [==============================] - 345s 1ms/step - loss: 0.4659 - accuracy: 0.8239 - val_loss: 0.5293 - val_accuracy: 0.8068\n",
            "Epoch 10/10\n",
            "284686/284686 [==============================] - 346s 1ms/step - loss: 0.4522 - accuracy: 0.8305 - val_loss: 0.5342 - val_accuracy: 0.8087\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f581b7adfd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WE8neNGgrcIZ",
        "outputId": "8e319489-d3b9-40d4-f322-7ae51decebec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "Y_val = [np.argmax(y, axis=None, out=None) for y in Y_val]\n",
        "Y_val[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 3, 2, 1, 4, 1, 4, 1, 1, 0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4EF6TsRSr575",
        "outputId": "ac663021-be3c-4365-e4cc-91c0761a83b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from sklearn import metrics\n",
        "y_pred=model1.predict_classes(X_val)\n",
        "\n",
        "print('Akurasi:',metrics.accuracy_score(y_pred,Y_val))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Akurasi: 0.808706373292868\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ktnH4DuDD-OG"
      },
      "source": [
        "# Predicting the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "novXVG3ZD-OT"
      },
      "source": [
        "## CNN model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrjVGQReD-OU"
      },
      "source": [
        "from keras.layers import Input, Dense, Embedding, Flatten\n",
        "from keras.layers import SpatialDropout1D\n",
        "from keras.layers.convolutional import Conv1D, MaxPooling1D\n",
        "from keras.models import Sequential"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTuMaBz5D-OW"
      },
      "source": [
        "model2 = Sequential()\n",
        "\n",
        "# Input / Embdedding\n",
        "model2.add(Embedding(max_features, 150, input_length=max_words))\n",
        "\n",
        "# CNN\n",
        "model2.add(SpatialDropout1D(0.2))\n",
        "\n",
        "model2.add(Conv1D(32, kernel_size=3, padding='same', activation='relu'))\n",
        "model2.add(MaxPooling1D(pool_size=2))\n",
        "\n",
        "model2.add(Conv1D(64, kernel_size=3, padding='same', activation='relu'))\n",
        "model2.add(MaxPooling1D(pool_size=2))\n",
        "\n",
        "model2.add(Flatten())\n",
        "\n",
        "# Output layer\n",
        "model2.add(Dense(5, activation='sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNDqnJW3D-OZ",
        "outputId": "8c40ff00-0203-40db-8307-26d56050dbe5"
      },
      "source": [
        "model2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model2.fit(X_train, Y_train, validation_data=(X_val, Y_val), epochs=epochs, batch_size=batch_size, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 284686 samples, validate on 94896 samples\n",
            "Epoch 1/3\n",
            "284686/284686 [==============================] - 138s 483us/step - loss: 0.8830 - acc: 0.6329 - val_loss: 0.7086 - val_acc: 0.7145\n",
            "Epoch 2/3\n",
            "284686/284686 [==============================] - 138s 486us/step - loss: 0.6148 - acc: 0.7567 - val_loss: 0.5950 - val_acc: 0.7685\n",
            "Epoch 3/3\n",
            "284686/284686 [==============================] - 139s 487us/step - loss: 0.5113 - acc: 0.8017 - val_loss: 0.5358 - val_acc: 0.7969\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f20c12f3ba8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dW6nHZNzD-Of",
        "outputId": "76015656-8466-46bf-ce58-669e815a38c1"
      },
      "source": [
        "pred2=model2.predict_classes(X_test,verbose=1)\n",
        "sub.Sentiment=pred2\n",
        "sub.to_csv('sub2.csv',index=False)\n",
        "#sub.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "66292/66292 [==============================] - 6s 84us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKVO8VxID-Oi"
      },
      "source": [
        "# CNN+BiLSTM\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_O96QkvD-Oj",
        "outputId": "58e2f205-76c5-481b-e212-167d88b41e9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        }
      },
      "source": [
        "model3= Sequential()\n",
        "model3.add(Embedding(max_features,100,input_length=max_words))\n",
        "model3.add(Conv1D(64,kernel_size=3,padding='same',activation='relu'))\n",
        "model3.add(MaxPooling1D(pool_size=2))\n",
        "model3.add(Dropout(0.25))\n",
        "model3.add(Bidirectional(LSTM(128,return_sequences=True)))\n",
        "model3.add(Dropout(0.3))\n",
        "model3.add(Flatten())\n",
        "model3.add(Dense(128,activation='relu'))\n",
        "model3.add(Dropout(0.5))\n",
        "model3.add(Dense(5,activation='softmax'))\n",
        "model3.compile(loss='categorical_crossentropy',optimizer=Adam(lr=0.001),metrics=['accuracy'])\n",
        "model3.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_4 (Embedding)      (None, 48, 100)           1372800   \n",
            "_________________________________________________________________\n",
            "conv1d_4 (Conv1D)            (None, 48, 64)            19264     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_4 (MaxPooling1 (None, 24, 64)            0         \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 24, 64)            0         \n",
            "_________________________________________________________________\n",
            "bidirectional_5 (Bidirection (None, 24, 256)           197632    \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 24, 256)           0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 6144)              0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 128)               786560    \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 5)                 645       \n",
            "=================================================================\n",
            "Total params: 2,376,901\n",
            "Trainable params: 2,376,901\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZrE7zi8D-Ol",
        "outputId": "e59450e4-45a5-4c8f-efc0-85b2c6c5f331",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%%time\n",
        "model3.fit(X_train, Y_train, validation_data=(X_val, Y_val),epochs=epochs, batch_size=batch_size, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 284686 samples, validate on 94896 samples\n",
            "Epoch 1/30\n",
            "284686/284686 [==============================] - 589s 2ms/step - loss: 0.8842 - accuracy: 0.6360 - val_loss: 0.6996 - val_accuracy: 0.7137\n",
            "Epoch 2/30\n",
            "284686/284686 [==============================] - 589s 2ms/step - loss: 0.6458 - accuracy: 0.7438 - val_loss: 0.6301 - val_accuracy: 0.7461\n",
            "Epoch 3/30\n",
            "284686/284686 [==============================] - 591s 2ms/step - loss: 0.5644 - accuracy: 0.7792 - val_loss: 0.5520 - val_accuracy: 0.7866\n",
            "Epoch 4/30\n",
            "284686/284686 [==============================] - 592s 2ms/step - loss: 0.5133 - accuracy: 0.8024 - val_loss: 0.5238 - val_accuracy: 0.8019\n",
            "Epoch 5/30\n",
            "284686/284686 [==============================] - 587s 2ms/step - loss: 0.4770 - accuracy: 0.8173 - val_loss: 0.5047 - val_accuracy: 0.8106\n",
            "Epoch 6/30\n",
            "284686/284686 [==============================] - 587s 2ms/step - loss: 0.4484 - accuracy: 0.8287 - val_loss: 0.5047 - val_accuracy: 0.8162\n",
            "Epoch 7/30\n",
            "284686/284686 [==============================] - 590s 2ms/step - loss: 0.4239 - accuracy: 0.8389 - val_loss: 0.4832 - val_accuracy: 0.8251\n",
            "Epoch 8/30\n",
            "284686/284686 [==============================] - 587s 2ms/step - loss: 0.4049 - accuracy: 0.8465 - val_loss: 0.4748 - val_accuracy: 0.8303\n",
            "Epoch 9/30\n",
            "284686/284686 [==============================] - 585s 2ms/step - loss: 0.3857 - accuracy: 0.8540 - val_loss: 0.4796 - val_accuracy: 0.8327\n",
            "Epoch 10/30\n",
            "284686/284686 [==============================] - 585s 2ms/step - loss: 0.3725 - accuracy: 0.8593 - val_loss: 0.4788 - val_accuracy: 0.8383\n",
            "Epoch 11/30\n",
            "284686/284686 [==============================] - 581s 2ms/step - loss: 0.3585 - accuracy: 0.8651 - val_loss: 0.4588 - val_accuracy: 0.8433\n",
            "Epoch 12/30\n",
            "284686/284686 [==============================] - 534s 2ms/step - loss: 0.3483 - accuracy: 0.8688 - val_loss: 0.4803 - val_accuracy: 0.8415\n",
            "Epoch 13/30\n",
            "284686/284686 [==============================] - 523s 2ms/step - loss: 0.3361 - accuracy: 0.8730 - val_loss: 0.4644 - val_accuracy: 0.8458\n",
            "Epoch 14/30\n",
            "284686/284686 [==============================] - 514s 2ms/step - loss: 0.3281 - accuracy: 0.8767 - val_loss: 0.4716 - val_accuracy: 0.8490\n",
            "Epoch 15/30\n",
            "284686/284686 [==============================] - 519s 2ms/step - loss: 0.3190 - accuracy: 0.8798 - val_loss: 0.4870 - val_accuracy: 0.8507\n",
            "Epoch 16/30\n",
            "284686/284686 [==============================] - 526s 2ms/step - loss: 0.3115 - accuracy: 0.8817 - val_loss: 0.4774 - val_accuracy: 0.8492\n",
            "Epoch 17/30\n",
            "284686/284686 [==============================] - 527s 2ms/step - loss: 0.3033 - accuracy: 0.8858 - val_loss: 0.4745 - val_accuracy: 0.8534\n",
            "Epoch 18/30\n",
            "284686/284686 [==============================] - 527s 2ms/step - loss: 0.2980 - accuracy: 0.8871 - val_loss: 0.4694 - val_accuracy: 0.8558\n",
            "Epoch 19/30\n",
            "284686/284686 [==============================] - 533s 2ms/step - loss: 0.2906 - accuracy: 0.8906 - val_loss: 0.4866 - val_accuracy: 0.8526\n",
            "Epoch 20/30\n",
            "284686/284686 [==============================] - 503s 2ms/step - loss: 0.2847 - accuracy: 0.8926 - val_loss: 0.4851 - val_accuracy: 0.8586\n",
            "Epoch 21/30\n",
            "284686/284686 [==============================] - 498s 2ms/step - loss: 0.2794 - accuracy: 0.8942 - val_loss: 0.4833 - val_accuracy: 0.8574\n",
            "Epoch 22/30\n",
            "284686/284686 [==============================] - 488s 2ms/step - loss: 0.2760 - accuracy: 0.8957 - val_loss: 0.4677 - val_accuracy: 0.8611\n",
            "Epoch 23/30\n",
            "284686/284686 [==============================] - 504s 2ms/step - loss: 0.2707 - accuracy: 0.8977 - val_loss: 0.5016 - val_accuracy: 0.8576\n",
            "Epoch 24/30\n",
            "284686/284686 [==============================] - 526s 2ms/step - loss: 0.2665 - accuracy: 0.8994 - val_loss: 0.4923 - val_accuracy: 0.8637\n",
            "Epoch 25/30\n",
            "284686/284686 [==============================] - 515s 2ms/step - loss: 0.2621 - accuracy: 0.9010 - val_loss: 0.5020 - val_accuracy: 0.8633\n",
            "Epoch 26/30\n",
            "284686/284686 [==============================] - 510s 2ms/step - loss: 0.2584 - accuracy: 0.9022 - val_loss: 0.5017 - val_accuracy: 0.8608\n",
            "Epoch 27/30\n",
            "284686/284686 [==============================] - 503s 2ms/step - loss: 0.2561 - accuracy: 0.9029 - val_loss: 0.5003 - val_accuracy: 0.8632\n",
            "Epoch 28/30\n",
            "284686/284686 [==============================] - 494s 2ms/step - loss: 0.2526 - accuracy: 0.9047 - val_loss: 0.4890 - val_accuracy: 0.8649\n",
            "Epoch 29/30\n",
            "284686/284686 [==============================] - 497s 2ms/step - loss: 0.2486 - accuracy: 0.9060 - val_loss: 0.5064 - val_accuracy: 0.8654\n",
            "Epoch 30/30\n",
            "284686/284686 [==============================] - 500s 2ms/step - loss: 0.2451 - accuracy: 0.9075 - val_loss: 0.5146 - val_accuracy: 0.8659\n",
            "CPU times: user 8h 34s, sys: 26min 4s, total: 8h 26min 39s\n",
            "Wall time: 4h 30min 2s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f5825fab048>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpti9SE_7z0C",
        "outputId": "115232ae-047d-4d05-9288-499f6adb89f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "Y_val = [np.argmax(y, axis=None, out=None) for y in Y_val]\n",
        "Y_val[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 3, 2, 1, 4, 1, 4, 1, 1, 0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uuklwHHI72wd",
        "outputId": "037e1d31-a1ad-4bf2-9045-c9532563091a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from sklearn import metrics\n",
        "y_pred=model3.predict_classes(X_val)\n",
        "\n",
        "print('Akurasi:',metrics.accuracy_score(y_pred,Y_val))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Akurasi: 0.8658742201989547\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}